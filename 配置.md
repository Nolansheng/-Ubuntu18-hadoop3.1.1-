
# Container exited with a non-zero exit code 2. Error file: prelaunch.err.
# <property>
<name>yarn.app.mapreduce.am.env</name>
<value>HADOOP_MAPRED_HOME=/opt/hadoop</value>
</property>
<property>
<name>mapreduce.map.env</name>
<value>HADOOP_MAPRED_HOME=/opt/hadoop</value>
</property>
<property>
<name>mapreduce.reduce.env</name>
<value>HADOOP_MAPRED_HOME=/opt/hadoop</value>
</property>

# 集群配置
## 1.准备工作
安装好ubuntu系统，记下每台机器IP地址

把源换成阿里云

基础的安装 vim,

## 2.环境
操作系统 Ubuntu Server 18.04

Hadoop 版本： Hadoop 3.1.1

jdk版本：jdk-10.0.2_linux_bin.tar.gz

## 3.将所有节点的IP地址写进“通讯录”
sudo vim /etc/hosts

## 4.创建hadoop用户，实现免密登陆

### 创建用户
sudo useradd -m hadoop -s /bin/bash

### 设置密码
sudo passwd hadoop

### 为账号增加管理员权限
sudo adduser hadoop sudo


### 更新系统
sudo apt-get update

### 切换至hadoop账号！！！！
su hadoop

### 安装SSH配置SSH免密登录
sudo apt-get install openssh-server

ssh localhost

首次登录会提示，输入yes，按提示输入密码，即可登录本机

我们需要免密登录。利用ssh-keygen生成密码，把公钥发送到要远程登录的机器上,具体原理见[SSH免密登录原理及配置](https://my.oschina.net/binxin/blog/651565)

exit(退出本地登录）

cd ~/.ssh/

ssh-keygen -t rsa

cat ./id_rsa.pub >> ./authorized_keys #再次尝试登录本地，无需密码验证

sudo apt install ssh pdsh ([pdsh的作用](http://blog.51cto.com/ixdba/1550184))

sudo sh -c "echo ssh > /etc/pdsh/rcmd_default"

ssh-copy-id -i ~/.ssh/id_rsa.pub  hadoopmaster/servera/serverb.... #将公钥发送到每一台机器

要把公钥发送给所有服务器，实现每两台机器直接都可免密访问！！！

## 5.配置Java环境
### 下载安装包上传到用户目录（自己想办法。。）

sudo mkdir /usr/java/ 创建目录作为JDK的安装目录，这里选择/usr/java

cd到文件下载的位置之后
sudo tar zxvf jdk-10.0.2_linux-x64_bin.tar.gz   解压文件到/usr/java目录下

sudo mv /usr/local/jdk-10.0.2 /usr/local/jdk  把jdk-10.0.2改名为jdk，方便配置

### 配置环境变量
sudo vim /etc/environment 把原来的内容删掉改为：


>PATH="/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:$JAVA_HOME/bin" 
export CLASSPATH=$JAVA_HOME/lib$JAVA_HOME/jre/lib 
export JAVA_HOME=/usr/java/jdk 
export JRE_HOME=${JAVA_HOME}/jre

sudo vim /etc/profile 在最后加入：

>JAVA_HOME=/usr/java/jdk
export JRE_HOME=/usr/java/jdk/jre
export CLASSPATH=.:$JAVA_HOME/lib:$JRE_HOME/lib:$CLASSPATH
export PATH=$JAVA_HOME/bin:$JRE_HOME/bin:$PATH

### 更新环境变量，查看java是否安装成功
source /etc/environment

source /etc/profile

java -version

## 6.配置Hadoop
### 下载安装包上传到用户目录

cd到下载目录 sudo tar -zxvf hadoop-3.1.1.tar.gaz -C /usr/local #解压到/usr/local/

sudo mv /usr/local/hadoop-3.1.1/ /usr/local/hadoop #将文件夹改名为hadoop

sudo chown -R hadoop /usr/local/hadoop #修改文件权限

cd /usr/local/hadoop

./bin/hadoop version #查看版本即是否安装成功

### 为了方便配置建议关闭防火墙以及卸载iptables

sudo ufw disable

sudo apt-get remove iptables

#### 配置文件路径/usr/local/hadoop/etc/hadoop，配置完之后拷贝到所有节点

vim core-site.xml 在最后加入

```
<configuration>
  <!-- 指定hdfs的nameservice为ns1 -->
  <property>
      <name>fs.defaultFS</name>
      <value>hdfs://hadoopmaster:9000</value>
  </property>
  <property>
      <name>io.file.buffer.size</name>
      <value>131072</value>
  </property>
</configuration>
```

**在hosts里面的时候，把主节点命名为hadoopmaster，在配置文件中就也是这个名称

vim hdfs-site.xml

```
<configuration>
<!-- Configurations for NameNode: -->
<property>
  <name>dfs.namenode.name.dir</name>
  <value>/var/lib/hadoop/hdfs/name/</value>
</property>
<property>
  <name>dfs.blocksize</name>
  <value>268435456</value>
</property>
<property>
  <name>dfs.namenode.handler.count  </name>
  <value>100</value>
</property>
<!-- Configurations for DataNode: -->
<property>
  <name>dfs.datanode.data.dir</name>
  <value>/var/lib/hadoop/hdfs/data/</value>
</property>
<property>
  <name>dfs.http.address</name>
  <value>servera:50070</value>
</property>
<property>
    <name>dfs.replication</name>
    <value>1</value>
</property>
</configuration>
```

vim yarn-site.xml

```
<configuration>
<!-- Site specific YARN configuration properties -->
<!-- Configurations for ResourceManager and NodeManager: -->
<!-- Configurations for ResourceManager: -->
  <property>
          <name>yarn.resourcemanager.hostname</name>
          <value>servera</value>
  </property>
<!-- Configurations for NodeManager: -->
  <property>
          <name>yarn.nodemanager.aux-services</name>
          <value>mapreduce_shuffle</value>
  </property>
<!-- Configurations for History Server (Needs to be moved elsewhere): -->
</configuration>
```

vim mapred-site.xml

```
<configuration>
  <!-- Configurations for MapReduce Applications: -->
  <property>
       <name>mapreduce.framework.name</name>
       <value>yarn</value>
   </property>
   <property>
        <name>mapred.job.tracker.http.address</name>
        <value>servera:50030</value>
   </property>
   <property>
        <name>mapred.task.tracker.http.address</name>
        <value>servera:50060</value>
   </property>
</configuration>
```

vim works
```
servera

serverb
.
.
.
```

**除了主节点!!!

### 把配置好的hadoop文件传到所有节点
scp /usr/local/hadoop/etc/hadoop/* servera:/usr/local/hadoop/etc/hadoop/

scp /usr/local/hadoop/etc/hadoop/* serverb:/usr/local/hadoop/etc/hadoop/


## 7.启动hadoop
/usr/local/hadoop/bin/hdfs namenode -format myClusterName  #初始化HDFS

/usr/local/hadoop/sbin/start-dfs.sh  #启动HDFS

/usr/local/hadoop/sbin/start-yarn.sh #启动yarn

**只需要在一台机器上执行以上命令！！！

### 在主机上用jps命令查看运行情况
jps

hadoopmaster节点
```
13905 ResourceManager
13669 SecondaryNameNode
17752 Jps
13374 NameNode
```

server节点
```
41413 Jps
39432 NodeManager
39244 DataNode
```



### 在HDFS中创建用户目录
./bin/hdfs dfs -mkdir -p /user/hadoop



